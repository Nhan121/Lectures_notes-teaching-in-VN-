{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import time\nt0 = time.time()","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pyspark","execution_count":2,"outputs":[{"output_type":"stream","text":"Collecting pyspark\n  Downloading pyspark-3.0.1.tar.gz (204.2 MB)\n\u001b[K     |████████████████████████████████| 204.2 MB 30 kB/s s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.9\n  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n\u001b[K     |████████████████████████████████| 198 kB 48.4 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.0.1-py2.py3-none-any.whl size=204612244 sha256=8fcf5c64215ae51379a043d7243868e4ab7d84e593cd6fe779d08f14f8da5b8e\n  Stored in directory: /root/.cache/pip/wheels/5e/34/fa/b37b5cef503fc5148b478b2495043ba61b079120b7ff379f9b\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9 pyspark-3.0.1\nNote: you may need to restart the kernel to use updated packages.\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pyspark import SparkConf, SparkContext\nfrom pyspark.sql import SQLContext, SparkSession\nprint('Installation takes %s seconds'%(time.time() - t0))","execution_count":3,"outputs":[{"output_type":"stream","text":"Installation takes 35.363959550857544 seconds\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"spark = SparkSession.builder \\\n                    .master(\"local\") \\\n                    .appName(\"Word Count\") \\\n                    .config(\"spark.some.config.option\", \"some-value\") \\\n                    .getOrCreate()\nspark","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<pyspark.sql.session.SparkSession at 0x7fc12172eb10>","text/html":"\n            <div>\n                <p><b>SparkSession - in-memory</b></p>\n                \n        <div>\n            <p><b>SparkContext</b></p>\n\n            <p><a href=\"http://184ee6d8fe44:4040\">Spark UI</a></p>\n\n            <dl>\n              <dt>Version</dt>\n                <dd><code>v3.0.1</code></dd>\n              <dt>Master</dt>\n                <dd><code>local</code></dd>\n              <dt>AppName</dt>\n                <dd><code>Word Count</code></dd>\n            </dl>\n        </div>\n        \n            </div>\n        "},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"## 1. Nhap du lieu thu cong"},{"metadata":{"trusted":true},"cell_type":"code","source":"sc = spark.sparkContext\nsqlContext = SQLContext(sc)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql import Row\ndf = sc.parallelize(\n    [\n        Row(name='Alice', age=5, height=80),\n        Row(name='Alice', age=5, height=80),\n        Row(name='Alice', age=10, height=80)\n    ]\n).toDF()\ndf.show()","execution_count":6,"outputs":[{"output_type":"stream","text":"+-----+---+------+\n| name|age|height|\n+-----+---+------+\n|Alice|  5|    80|\n|Alice|  5|    80|\n|Alice| 10|    80|\n+-----+---+------+\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SQLContext.registerDataFrameAsTable(sc, df = df, tableName = \"table1\")","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"help(SQLContext.sql)","execution_count":8,"outputs":[{"output_type":"stream","text":"Help on function sql in module pyspark.sql.context:\n\nsql(self, sqlQuery)\n    Returns a :class:`DataFrame` representing the result of the given query.\n    \n    :return: :class:`DataFrame`\n    \n    >>> sqlContext.registerDataFrameAsTable(df, \"table1\")\n    >>> df2 = sqlContext.sql(\"SELECT field1 AS f1, field2 as f2 from table1\")\n    >>> df2.collect()\n    [Row(f1=1, f2='row1'), Row(f1=2, f2='row2'), Row(f1=3, f2='row3')]\n    \n    .. versionadded:: 1.0\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"query = spark.sql(\"SELECT * FROM table1\")\nquery.collect()","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"[Row(name='Alice', age=5, height=80),\n Row(name='Alice', age=5, height=80),\n Row(name='Alice', age=10, height=80)]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"query.show()","execution_count":10,"outputs":[{"output_type":"stream","text":"+-----+---+------+\n| name|age|height|\n+-----+---+------+\n|Alice|  5|    80|\n|Alice|  5|    80|\n|Alice| 10|    80|\n+-----+---+------+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 2. Tai du lieu co san~\n### 2.1. Type = `csv`"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv(r'../input/covid19s-impact-on-airport-traffic/covid_impact_on_airport_traffic.csv')\nprint(df.shape)\ndf.head()","execution_count":11,"outputs":[{"output_type":"stream","text":"(5936, 11)\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"  AggregationMethod        Date  Version      AirportName  PercentOfBaseline  \\\n0             Daily  2020-07-05      1.0  Kingsford Smith                 52   \n1             Daily  2020-05-28      1.0  Kingsford Smith                 61   \n2             Daily  2020-05-07      1.0  Kingsford Smith                 62   \n3             Daily  2020-06-24      1.0  Kingsford Smith                 58   \n4             Daily  2020-08-05      1.0  Kingsford Smith                 20   \n\n                                    Centroid    City            State  \\\n0  POINT(151.180087713813 -33.9459774986125)  Sydney  New South Wales   \n1  POINT(151.180087713813 -33.9459774986125)  Sydney  New South Wales   \n2  POINT(151.180087713813 -33.9459774986125)  Sydney  New South Wales   \n3  POINT(151.180087713813 -33.9459774986125)  Sydney  New South Wales   \n4  POINT(151.180087713813 -33.9459774986125)  Sydney  New South Wales   \n\n  ISO_3166_2    Country                                          Geography  \n0         AU  Australia  POLYGON((151.164354085922 -33.9301772341877, 1...  \n1         AU  Australia  POLYGON((151.164354085922 -33.9301772341877, 1...  \n2         AU  Australia  POLYGON((151.164354085922 -33.9301772341877, 1...  \n3         AU  Australia  POLYGON((151.164354085922 -33.9301772341877, 1...  \n4         AU  Australia  POLYGON((151.164354085922 -33.9301772341877, 1...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AggregationMethod</th>\n      <th>Date</th>\n      <th>Version</th>\n      <th>AirportName</th>\n      <th>PercentOfBaseline</th>\n      <th>Centroid</th>\n      <th>City</th>\n      <th>State</th>\n      <th>ISO_3166_2</th>\n      <th>Country</th>\n      <th>Geography</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Daily</td>\n      <td>2020-07-05</td>\n      <td>1.0</td>\n      <td>Kingsford Smith</td>\n      <td>52</td>\n      <td>POINT(151.180087713813 -33.9459774986125)</td>\n      <td>Sydney</td>\n      <td>New South Wales</td>\n      <td>AU</td>\n      <td>Australia</td>\n      <td>POLYGON((151.164354085922 -33.9301772341877, 1...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Daily</td>\n      <td>2020-05-28</td>\n      <td>1.0</td>\n      <td>Kingsford Smith</td>\n      <td>61</td>\n      <td>POINT(151.180087713813 -33.9459774986125)</td>\n      <td>Sydney</td>\n      <td>New South Wales</td>\n      <td>AU</td>\n      <td>Australia</td>\n      <td>POLYGON((151.164354085922 -33.9301772341877, 1...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Daily</td>\n      <td>2020-05-07</td>\n      <td>1.0</td>\n      <td>Kingsford Smith</td>\n      <td>62</td>\n      <td>POINT(151.180087713813 -33.9459774986125)</td>\n      <td>Sydney</td>\n      <td>New South Wales</td>\n      <td>AU</td>\n      <td>Australia</td>\n      <td>POLYGON((151.164354085922 -33.9301772341877, 1...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Daily</td>\n      <td>2020-06-24</td>\n      <td>1.0</td>\n      <td>Kingsford Smith</td>\n      <td>58</td>\n      <td>POINT(151.180087713813 -33.9459774986125)</td>\n      <td>Sydney</td>\n      <td>New South Wales</td>\n      <td>AU</td>\n      <td>Australia</td>\n      <td>POLYGON((151.164354085922 -33.9301772341877, 1...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Daily</td>\n      <td>2020-08-05</td>\n      <td>1.0</td>\n      <td>Kingsford Smith</td>\n      <td>20</td>\n      <td>POINT(151.180087713813 -33.9459774986125)</td>\n      <td>Sydney</td>\n      <td>New South Wales</td>\n      <td>AU</td>\n      <td>Australia</td>\n      <td>POLYGON((151.164354085922 -33.9301772341877, 1...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### convert csv to parquert"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = spark.read.format(\"csv\").option(\"header\", \"true\").load(r'../input/covid19s-impact-on-airport-traffic/covid_impact_on_airport_traffic.csv')\ndf.show(5)","execution_count":12,"outputs":[{"output_type":"stream","text":"+-----------------+----------+-------+---------------+-----------------+--------------------+------+---------------+----------+---------+--------------------+\n|AggregationMethod|      Date|Version|    AirportName|PercentOfBaseline|            Centroid|  City|          State|ISO_3166_2|  Country|           Geography|\n+-----------------+----------+-------+---------------+-----------------+--------------------+------+---------------+----------+---------+--------------------+\n|            Daily|2020-07-05|    1.0|Kingsford Smith|               52|POINT(151.1800877...|Sydney|New South Wales|        AU|Australia|POLYGON((151.1643...|\n|            Daily|2020-05-28|    1.0|Kingsford Smith|               61|POINT(151.1800877...|Sydney|New South Wales|        AU|Australia|POLYGON((151.1643...|\n|            Daily|2020-05-07|    1.0|Kingsford Smith|               62|POINT(151.1800877...|Sydney|New South Wales|        AU|Australia|POLYGON((151.1643...|\n|            Daily|2020-06-24|    1.0|Kingsford Smith|               58|POINT(151.1800877...|Sydney|New South Wales|        AU|Australia|POLYGON((151.1643...|\n|            Daily|2020-08-05|    1.0|Kingsford Smith|               20|POINT(151.1800877...|Sydney|New South Wales|        AU|Australia|POLYGON((151.1643...|\n+-----------------+----------+-------+---------------+-----------------+--------------------+------+---------------+----------+---------+--------------------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### Luu dataframe moi tao voi ten table2"},{"metadata":{"trusted":true},"cell_type":"code","source":"SQLContext.registerDataFrameAsTable(sc, df = df, tableName = \"table2\")","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Example. Create a query to count `country` from `table2`"},{"metadata":{"trusted":true},"cell_type":"code","source":"query = spark.sql(\"\"\"\n                    SELECT country, COUNT(*) \n                    FROM table2 \n                    GROUP BY country\"\"\")\nquery.show()","execution_count":14,"outputs":[{"output_type":"stream","text":"+--------------------+--------+\n|             country|count(1)|\n+--------------------+--------+\n|United States of ...|    3642|\n|               Chile|     195|\n|              Canada|    1888|\n|           Australia|     211|\n+--------------------+--------+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2.2. Load `txt.file`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = spark.read.text(r'../input/poetry/Lil_Wayne.txt')\ndf.show(5)","execution_count":15,"outputs":[{"output_type":"stream","text":"+--------------------+\n|               value|\n+--------------------+\n|They call me Mr C...|\n|Of the deads fore...|\n|Spilled the heart...|\n|I will put them b...|\n|Gracias Im crazy ...|\n+--------------------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Example 3. Extract unique `value` started with letter `A` and has almost 15 characters."},{"metadata":{"trusted":true},"cell_type":"code","source":"SQLContext.registerDataFrameAsTable(sc, df = df, tableName = \"table3\")\n\nquery_2 = spark.sql(\"\"\"\n                    SELECT DISTINCT(*), length(value) AS len\n                    FROM table3 \n                    WHERE value LIKE 'A%' \n                          AND length(value) < 15\n                    ORDER BY len\n                    \"\"\")\nquery_2.show()","execution_count":16,"outputs":[{"output_type":"stream","text":"+--------------+---+\n|         value|len|\n+--------------+---+\n|            Ai|  2|\n|           Aha|  3|\n|           Aye|  3|\n|         And I|  5|\n|       Alright|  7|\n|       And man|  7|\n|      Assholes|  8|\n|      Ay Wayne|  8|\n|  A damn shame| 12|\n| Aint no issue| 13|\n|Are right here| 14|\n+--------------+---+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### 2.3. Load `parquet.file`"},{"metadata":{"trusted":true},"cell_type":"code","source":"query.write.parquet('customer_parquet')\ndf = sqlContext.read.parquet('customer_parquet')\ndf.show()","execution_count":17,"outputs":[{"output_type":"stream","text":"+----------+------+---+\n|CustomerID|Gender|Age|\n+----------+------+---+\n|         1|  Male| 19|\n|         2|  Male| 21|\n|         3|Female| 20|\n|         4|Female| 23|\n|         5|Female| 31|\n|         6|Female| 22|\n|         7|Female| 35|\n|         8|Female| 23|\n|         9|  Male| 64|\n|        10|Female| 30|\n|        11|  Male| 67|\n|        12|Female| 35|\n|        13|Female| 58|\n|        14|Female| 24|\n|        15|  Male| 37|\n|        16|  Male| 22|\n|        17|Female| 35|\n|        18|  Male| 20|\n|        19|  Male| 52|\n|        20|Female| 35|\n+----------+------+---+\nonly showing top 20 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 3. Save the `query result` as `sqlite, csv`"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nquery.write.csv('data_temp_csv')\nquery.write.parquet('data_temp_parquet')","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}