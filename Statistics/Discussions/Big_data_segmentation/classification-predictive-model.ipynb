{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install xlrd\n!pip install openpyxl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import dataiku\n#from dataiku import pandasutils as pdu\nimport pandas as pd\nimport time","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\nclass Classifier_comparision:\n    def __init__(self, X, y, test_size, train_size, stratified = True):\n        self.X = X\n        self.y = y\n        self.test_size = test_size\n        self.train_size = train_size\n        self.stratified = stratified\n        \n    def make_result(self):\n        #Machine Learning Algorithm (MLA) Selection and Initialization\n        MLA = [\n            #Ensemble Methods\n            ensemble.AdaBoostClassifier(),\n            ensemble.BaggingClassifier(),\n            ensemble.ExtraTreesClassifier(),\n            ensemble.GradientBoostingClassifier(),\n            ensemble.RandomForestClassifier(),\n\n            #Gaussian Processes\n            gaussian_process.GaussianProcessClassifier(),\n\n            #GLM\n            linear_model.LogisticRegressionCV(),\n            linear_model.PassiveAggressiveClassifier(),\n            linear_model.RidgeClassifierCV(),\n            linear_model.SGDClassifier(),\n            linear_model.Perceptron(),\n\n            #Navies Bayes\n            naive_bayes.BernoulliNB(),\n            naive_bayes.GaussianNB(),\n\n            #Nearest Neighbor\n            neighbors.KNeighborsClassifier(),\n\n            #SVM\n            svm.SVC(probability=True, kernel = 'linear', C = 1, gamma = 1),\n            svm.SVC(probability=True, kernel = 'poly', C = 1, gamma = 1),\n            svm.SVC(probability=True, kernel = 'rbf', C = 1, gamma = 1),\n            svm.SVC(probability=True, kernel = 'sigmoid'),\n            svm.NuSVC(probability=True),\n            svm.LinearSVC(),\n\n            #Trees    \n            tree.DecisionTreeClassifier(),\n            tree.ExtraTreeClassifier(),\n\n            #Discriminant Analysis\n            discriminant_analysis.LinearDiscriminantAnalysis(),\n            discriminant_analysis.QuadraticDiscriminantAnalysis(),\n\n            #xgboost: http://xgboost.readthedocs.io/en/latest/model.html\n            XGBClassifier(eval_metric='mlogloss')    \n            ]\n\n        from sklearn.model_selection import train_test_split, ShuffleSplit, StratifiedShuffleSplit\n        # prepare\n        cv_split_1 = ShuffleSplit(n_splits = 10, test_size = .25, train_size = .55, random_state = 33)        \n        cv_split_2 = StratifiedShuffleSplit(n_splits = 10, test_size = .25, train_size = .55, random_state = 33)\n        # pre-test\n        X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, \n                                                            test_size = 0.25, random_state = 33)\n        \n        from sklearn import model_selection\n        MLA_model_name = []\n        run_times = []\n        train_acc = []\n        test_acc = []\n        test_rep = []\n        test_mat = []\n        best_params = []\n\n        for idx, alg in enumerate(MLA):\n            t0 = time.time()\n            #set name and parameters\n            MLA_model_name.append(alg.__class__.__name__)    \n            best_params.append(str(alg.get_params()))\n\n            #score model with cross validation:\n            if self.stratified == 1:\n                cv_results = model_selection.cross_validate(alg, self.X, self.y, cv = cv_split_1, return_train_score = True)\n            else:\n                cv_results = model_selection.cross_validate(alg, self.X, self.y, cv = cv_split_2, return_train_score = True)\n                \n            train_acc.append(cv_results['train_score'].mean())\n            test_acc.append(cv_results['test_score'].mean())\n            run_times.append(time.time() - t0)\n            \n            # pre-test\n            alg.fit(X_train, y_train)\n\n            y_pr_tr = alg.predict(X_train)\n            y_pr_tt = alg.predict(X_test)\n            test_mat.append(confusion_matrix(y_test, y_pr_tt))\n            test_rep.append(classification_report(y_test, y_pr_tt))\n            \n        import pandas as pd\n        df = pd.DataFrame({\"MLA_model_name\": MLA_model_name,\n                           \"best_params\": best_params,\n                           \"train_acc_kfold\": train_acc,\n                           \"test_acc_kfold\": test_acc,\n                           \"run_time\": run_times,\n                           \"conf_test_matrix\": test_mat,\n                           \"clf_test_report\": test_rep\n                          })\n        return df.sort_values(by=['test_acc_kfold', 'train_acc_kfold'], ascending=False)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mydataset = dataiku.Dataset(\"SBN\")\n#mydataset_df = mydataset.get_dataframe()\nmydataset_df = pd.read_excel(r\"../input/nhandv6/Swiss Bank Notes.xlsx\", sheet_name = 'Sheet1')\nmydataset_df.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   Length  Height (left)  Height (right)  Inner Frame (lower)  \\\n0   214.8          131.0           131.1                  9.0   \n1   214.6          129.7           129.7                  8.1   \n2   214.8          129.7           129.7                  8.7   \n3   214.8          129.7           129.6                  7.5   \n4   215.0          129.6           129.7                 10.4   \n\n   Inner Frame (upper)  Diagonal  \n0                  9.7     141.0  \n1                  9.5     141.7  \n2                  9.6     142.2  \n3                 10.4     142.0  \n4                  7.7     141.8  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Height (left)</th>\n      <th>Height (right)</th>\n      <th>Inner Frame (lower)</th>\n      <th>Inner Frame (upper)</th>\n      <th>Diagonal</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>214.8</td>\n      <td>131.0</td>\n      <td>131.1</td>\n      <td>9.0</td>\n      <td>9.7</td>\n      <td>141.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>214.6</td>\n      <td>129.7</td>\n      <td>129.7</td>\n      <td>8.1</td>\n      <td>9.5</td>\n      <td>141.7</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>214.8</td>\n      <td>129.7</td>\n      <td>129.7</td>\n      <td>8.7</td>\n      <td>9.6</td>\n      <td>142.2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>214.8</td>\n      <td>129.7</td>\n      <td>129.6</td>\n      <td>7.5</td>\n      <td>10.4</td>\n      <td>142.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>215.0</td>\n      <td>129.6</td>\n      <td>129.7</td>\n      <td>10.4</td>\n      <td>7.7</td>\n      <td>141.8</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"SWB_df = mydataset_df.copy()\nSWB_df['target'] = 100*[1] + 100*[0]\nSWB_df.head()","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"   Length  Height (left)  Height (right)  Inner Frame (lower)  \\\n0   214.8          131.0           131.1                  9.0   \n1   214.6          129.7           129.7                  8.1   \n2   214.8          129.7           129.7                  8.7   \n3   214.8          129.7           129.6                  7.5   \n4   215.0          129.6           129.7                 10.4   \n\n   Inner Frame (upper)  Diagonal  target  \n0                  9.7     141.0       1  \n1                  9.5     141.7       1  \n2                  9.6     142.2       1  \n3                 10.4     142.0       1  \n4                  7.7     141.8       1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Length</th>\n      <th>Height (left)</th>\n      <th>Height (right)</th>\n      <th>Inner Frame (lower)</th>\n      <th>Inner Frame (upper)</th>\n      <th>Diagonal</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>214.8</td>\n      <td>131.0</td>\n      <td>131.1</td>\n      <td>9.0</td>\n      <td>9.7</td>\n      <td>141.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>214.6</td>\n      <td>129.7</td>\n      <td>129.7</td>\n      <td>8.1</td>\n      <td>9.5</td>\n      <td>141.7</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>214.8</td>\n      <td>129.7</td>\n      <td>129.7</td>\n      <td>8.7</td>\n      <td>9.6</td>\n      <td>142.2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>214.8</td>\n      <td>129.7</td>\n      <td>129.6</td>\n      <td>7.5</td>\n      <td>10.4</td>\n      <td>142.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>215.0</td>\n      <td>129.6</td>\n      <td>129.7</td>\n      <td>10.4</td>\n      <td>7.7</td>\n      <td>141.8</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings('ignore', category = UserWarning)\nwarnings.filterwarnings('ignore', category = Warning)\n\nX = SWB_df.iloc[:, :-1]\ny = SWB_df.iloc[:, -1]\ncc = Classifier_comparision(X, y, test_size = 0.25, train_size = 0.6)\n%time res = cc.make_result()\nres","execution_count":8,"outputs":[{"output_type":"stream","text":"CPU times: user 13.5 s, sys: 827 ms, total: 14.3 s\nWall time: 12.2 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"                   MLA_model_name  \\\n2            ExtraTreesClassifier   \n4          RandomForestClassifier   \n9                   SGDClassifier   \n13           KNeighborsClassifier   \n18                          NuSVC   \n5       GaussianProcessClassifier   \n14                            SVC   \n8               RidgeClassifierCV   \n22     LinearDiscriminantAnalysis   \n23  QuadraticDiscriminantAnalysis   \n12                     GaussianNB   \n6            LogisticRegressionCV   \n1               BaggingClassifier   \n24                  XGBClassifier   \n16                            SVC   \n0              AdaBoostClassifier   \n3      GradientBoostingClassifier   \n15                            SVC   \n20         DecisionTreeClassifier   \n19                      LinearSVC   \n21            ExtraTreeClassifier   \n10                     Perceptron   \n17                            SVC   \n7     PassiveAggressiveClassifier   \n11                    BernoulliNB   \n\n                                          best_params  train_acc_kfold  \\\n2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...         1.000000   \n4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...         1.000000   \n9   {'alpha': 0.0001, 'average': False, 'class_wei...         1.000000   \n13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...         0.998182   \n18  {'break_ties': False, 'cache_size': 200, 'clas...         0.996364   \n5   {'copy_X_train': True, 'kernel': None, 'max_it...         0.995455   \n14  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.995455   \n8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...         0.994545   \n22  {'covariance_estimator': None, 'n_components':...         0.994545   \n23  {'priors': None, 'reg_param': 0.0, 'store_cova...         0.994545   \n12           {'priors': None, 'var_smoothing': 1e-09}         0.993636   \n6   {'Cs': 10, 'class_weight': None, 'cv': None, '...         0.999091   \n1   {'base_estimator': None, 'bootstrap': True, 'b...         0.996364   \n24  {'objective': 'binary:logistic', 'use_label_en...         0.995455   \n16  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.996364   \n0   {'algorithm': 'SAMME.R', 'base_estimator': Non...         1.000000   \n3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...         1.000000   \n15  {'C': 1, 'break_ties': False, 'cache_size': 20...         1.000000   \n20  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n19  {'C': 1.0, 'class_weight': None, 'dual': True,...         0.956364   \n21  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n10  {'alpha': 0.0001, 'class_weight': None, 'early...         0.536364   \n17  {'C': 1.0, 'break_ties': False, 'cache_size': ...         0.574545   \n7   {'C': 1.0, 'average': False, 'class_weight': N...         0.503636   \n11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...         0.530909   \n\n    test_acc_kfold  run_time    conf_test_matrix  \\\n2            1.000  1.512226  [[25, 0], [0, 25]]   \n4            1.000  2.078298  [[24, 1], [0, 25]]   \n9            1.000  0.071239  [[25, 0], [0, 25]]   \n13           1.000  0.160594  [[25, 0], [0, 25]]   \n18           1.000  0.106560  [[25, 0], [0, 25]]   \n5            1.000  0.262364  [[25, 0], [0, 25]]   \n14           1.000  0.082308  [[25, 0], [0, 25]]   \n8            1.000  0.104718  [[25, 0], [0, 25]]   \n22           1.000  0.078689  [[25, 0], [0, 25]]   \n23           1.000  0.086085  [[25, 0], [0, 25]]   \n12           1.000  0.075782  [[25, 0], [0, 25]]   \n6            0.996  3.548686  [[25, 0], [0, 25]]   \n1            0.992  0.330783  [[24, 1], [0, 25]]   \n24           0.992  0.298748  [[24, 1], [0, 25]]   \n16           0.988  0.110408  [[25, 0], [0, 25]]   \n0            0.988  0.718237  [[25, 0], [0, 25]]   \n3            0.988  0.592797  [[24, 1], [0, 25]]   \n15           0.988  0.082933  [[25, 0], [0, 25]]   \n20           0.988  0.067193  [[24, 1], [0, 25]]   \n19           0.970  0.124182  [[3, 22], [0, 25]]   \n21           0.952  0.068686  [[21, 4], [0, 25]]   \n10           0.564  0.073405  [[25, 0], [25, 0]]   \n17           0.492  0.135331  [[25, 0], [1, 24]]   \n7            0.480  0.075092  [[25, 0], [25, 0]]   \n11           0.444  0.078323  [[25, 0], [25, 0]]   \n\n                                      clf_test_report  \n2                 precision    recall  f1-score   ...  \n4                 precision    recall  f1-score   ...  \n9                 precision    recall  f1-score   ...  \n13                precision    recall  f1-score   ...  \n18                precision    recall  f1-score   ...  \n5                 precision    recall  f1-score   ...  \n14                precision    recall  f1-score   ...  \n8                 precision    recall  f1-score   ...  \n22                precision    recall  f1-score   ...  \n23                precision    recall  f1-score   ...  \n12                precision    recall  f1-score   ...  \n6                 precision    recall  f1-score   ...  \n1                 precision    recall  f1-score   ...  \n24                precision    recall  f1-score   ...  \n16                precision    recall  f1-score   ...  \n0                 precision    recall  f1-score   ...  \n3                 precision    recall  f1-score   ...  \n15                precision    recall  f1-score   ...  \n20                precision    recall  f1-score   ...  \n19                precision    recall  f1-score   ...  \n21                precision    recall  f1-score   ...  \n10                precision    recall  f1-score   ...  \n17                precision    recall  f1-score   ...  \n7                 precision    recall  f1-score   ...  \n11                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesClassifier</td>\n      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>1.512226</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>2.078298</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SGDClassifier</td>\n      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>0.071239</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsClassifier</td>\n      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n      <td>0.998182</td>\n      <td>1.000</td>\n      <td>0.160594</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NuSVC</td>\n      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n      <td>0.996364</td>\n      <td>1.000</td>\n      <td>0.106560</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GaussianProcessClassifier</td>\n      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n      <td>0.995455</td>\n      <td>1.000</td>\n      <td>0.262364</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.995455</td>\n      <td>1.000</td>\n      <td>0.082308</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeClassifierCV</td>\n      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.104718</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>{'covariance_estimator': None, 'n_components':...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.078689</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>QuadraticDiscriminantAnalysis</td>\n      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.086085</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GaussianNB</td>\n      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n      <td>0.993636</td>\n      <td>1.000</td>\n      <td>0.075782</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LogisticRegressionCV</td>\n      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n      <td>0.999091</td>\n      <td>0.996</td>\n      <td>3.548686</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingClassifier</td>\n      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n      <td>0.996364</td>\n      <td>0.992</td>\n      <td>0.330783</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n      <td>0.995455</td>\n      <td>0.992</td>\n      <td>0.298748</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.996364</td>\n      <td>0.988</td>\n      <td>0.110408</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n      <td>1.000000</td>\n      <td>0.988</td>\n      <td>0.718237</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n      <td>1.000000</td>\n      <td>0.988</td>\n      <td>0.592797</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>1.000000</td>\n      <td>0.988</td>\n      <td>0.082933</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.988</td>\n      <td>0.067193</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LinearSVC</td>\n      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n      <td>0.956364</td>\n      <td>0.970</td>\n      <td>0.124182</td>\n      <td>[[3, 22], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.952</td>\n      <td>0.068686</td>\n      <td>[[21, 4], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Perceptron</td>\n      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n      <td>0.536364</td>\n      <td>0.564</td>\n      <td>0.073405</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC</td>\n      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n      <td>0.574545</td>\n      <td>0.492</td>\n      <td>0.135331</td>\n      <td>[[25, 0], [1, 24]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PassiveAggressiveClassifier</td>\n      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n      <td>0.503636</td>\n      <td>0.480</td>\n      <td>0.075092</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.530909</td>\n      <td>0.444</td>\n      <td>0.078323</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(res['clf_test_report'][0])\nprint(res['conf_test_matrix'][0])","execution_count":9,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        25\n           1       1.00      1.00      1.00        25\n\n    accuracy                           1.00        50\n   macro avg       1.00      1.00      1.00        50\nweighted avg       1.00      1.00      1.00        50\n\n[[25  0]\n [ 0 25]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\nrate = 0.95\npca = PCA(rate)\nX_pca = pca.fit_transform(X)\nn1 = X.shape[1]\nn2 = X_pca.shape[1]\nprint(\"{} is the number of dimension that keep {}% information from the original dataset {}.\"\n      .format(n2, int(rate*100), n1))\n\n# Evaluate\ncc_pca = Classifier_comparision(X_pca, y, test_size = 0.25, train_size = 0.6)\n%time cc_pca.make_result()","execution_count":10,"outputs":[{"output_type":"stream","text":"4 is the number of dimension that keep 95% information from the original dataset 6.\nCPU times: user 9.11 s, sys: 617 ms, total: 9.72 s\nWall time: 7.93 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                   MLA_model_name  \\\n2            ExtraTreesClassifier   \n19                      LinearSVC   \n13           KNeighborsClassifier   \n5       GaussianProcessClassifier   \n14                            SVC   \n17                            SVC   \n8               RidgeClassifierCV   \n22     LinearDiscriminantAnalysis   \n23  QuadraticDiscriminantAnalysis   \n4          RandomForestClassifier   \n18                          NuSVC   \n7     PassiveAggressiveClassifier   \n10                     Perceptron   \n9                   SGDClassifier   \n6            LogisticRegressionCV   \n0              AdaBoostClassifier   \n3      GradientBoostingClassifier   \n20         DecisionTreeClassifier   \n24                  XGBClassifier   \n12                     GaussianNB   \n1               BaggingClassifier   \n16                            SVC   \n11                    BernoulliNB   \n15                            SVC   \n21            ExtraTreeClassifier   \n\n                                          best_params  train_acc_kfold  \\\n2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...         1.000000   \n19  {'C': 1.0, 'class_weight': None, 'dual': True,...         0.999091   \n13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...         0.998182   \n5   {'copy_X_train': True, 'kernel': None, 'max_it...         0.995455   \n14  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.995455   \n17  {'C': 1.0, 'break_ties': False, 'cache_size': ...         0.995455   \n8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...         0.994545   \n22  {'covariance_estimator': None, 'n_components':...         0.994545   \n23  {'priors': None, 'reg_param': 0.0, 'store_cova...         0.994545   \n4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...         1.000000   \n18  {'break_ties': False, 'cache_size': 200, 'clas...         0.994545   \n7   {'C': 1.0, 'average': False, 'class_weight': N...         1.000000   \n10  {'alpha': 0.0001, 'class_weight': None, 'early...         1.000000   \n9   {'alpha': 0.0001, 'average': False, 'class_wei...         0.999091   \n6   {'Cs': 10, 'class_weight': None, 'cv': None, '...         0.998182   \n0   {'algorithm': 'SAMME.R', 'base_estimator': Non...         1.000000   \n3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...         1.000000   \n20  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n24  {'objective': 'binary:logistic', 'use_label_en...         1.000000   \n12           {'priors': None, 'var_smoothing': 1e-09}         0.997273   \n1   {'base_estimator': None, 'bootstrap': True, 'b...         1.000000   \n16  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.995455   \n11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...         0.981818   \n15  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.997273   \n21  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n\n    test_acc_kfold  run_time    conf_test_matrix  \\\n2            1.000  1.466029  [[25, 0], [0, 25]]   \n19           1.000  0.020681  [[25, 0], [0, 25]]   \n13           1.000  0.104276  [[25, 0], [0, 25]]   \n5            1.000  0.154420  [[25, 0], [0, 25]]   \n14           1.000  0.029946  [[25, 0], [0, 25]]   \n17           1.000  0.031741  [[25, 0], [1, 24]]   \n8            1.000  0.040701  [[25, 0], [0, 25]]   \n22           1.000  0.025850  [[25, 0], [0, 25]]   \n23           1.000  0.023332  [[25, 0], [0, 25]]   \n4            0.998  2.041246  [[24, 1], [0, 25]]   \n18           0.998  0.059211  [[25, 0], [0, 25]]   \n7            0.996  0.023410  [[25, 0], [25, 0]]   \n10           0.996  0.030286  [[25, 0], [25, 0]]   \n9            0.996  0.026746  [[25, 0], [0, 25]]   \n6            0.996  1.257428  [[25, 0], [0, 25]]   \n0            0.992  0.045213  [[25, 0], [0, 25]]   \n3            0.992  0.522662  [[24, 1], [0, 25]]   \n20           0.992  0.020637  [[24, 1], [0, 25]]   \n24           0.992  0.268748  [[24, 1], [0, 25]]   \n12           0.992  0.025370  [[25, 0], [0, 25]]   \n1            0.990  0.280876  [[24, 1], [0, 25]]   \n16           0.988  0.058963  [[25, 0], [0, 25]]   \n11           0.986  0.027319  [[25, 0], [25, 0]]   \n15           0.980  0.031632  [[25, 0], [0, 25]]   \n21           0.968  0.020701  [[24, 1], [0, 25]]   \n\n                                      clf_test_report  \n2                 precision    recall  f1-score   ...  \n19                precision    recall  f1-score   ...  \n13                precision    recall  f1-score   ...  \n5                 precision    recall  f1-score   ...  \n14                precision    recall  f1-score   ...  \n17                precision    recall  f1-score   ...  \n8                 precision    recall  f1-score   ...  \n22                precision    recall  f1-score   ...  \n23                precision    recall  f1-score   ...  \n4                 precision    recall  f1-score   ...  \n18                precision    recall  f1-score   ...  \n7                 precision    recall  f1-score   ...  \n10                precision    recall  f1-score   ...  \n9                 precision    recall  f1-score   ...  \n6                 precision    recall  f1-score   ...  \n0                 precision    recall  f1-score   ...  \n3                 precision    recall  f1-score   ...  \n20                precision    recall  f1-score   ...  \n24                precision    recall  f1-score   ...  \n12                precision    recall  f1-score   ...  \n1                 precision    recall  f1-score   ...  \n16                precision    recall  f1-score   ...  \n11                precision    recall  f1-score   ...  \n15                precision    recall  f1-score   ...  \n21                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesClassifier</td>\n      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n      <td>1.000000</td>\n      <td>1.000</td>\n      <td>1.466029</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LinearSVC</td>\n      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n      <td>0.999091</td>\n      <td>1.000</td>\n      <td>0.020681</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsClassifier</td>\n      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n      <td>0.998182</td>\n      <td>1.000</td>\n      <td>0.104276</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GaussianProcessClassifier</td>\n      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n      <td>0.995455</td>\n      <td>1.000</td>\n      <td>0.154420</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.995455</td>\n      <td>1.000</td>\n      <td>0.029946</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC</td>\n      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n      <td>0.995455</td>\n      <td>1.000</td>\n      <td>0.031741</td>\n      <td>[[25, 0], [1, 24]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeClassifierCV</td>\n      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.040701</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>{'covariance_estimator': None, 'n_components':...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.025850</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>QuadraticDiscriminantAnalysis</td>\n      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n      <td>0.994545</td>\n      <td>1.000</td>\n      <td>0.023332</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n      <td>1.000000</td>\n      <td>0.998</td>\n      <td>2.041246</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NuSVC</td>\n      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n      <td>0.994545</td>\n      <td>0.998</td>\n      <td>0.059211</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PassiveAggressiveClassifier</td>\n      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n      <td>1.000000</td>\n      <td>0.996</td>\n      <td>0.023410</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Perceptron</td>\n      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n      <td>1.000000</td>\n      <td>0.996</td>\n      <td>0.030286</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SGDClassifier</td>\n      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n      <td>0.999091</td>\n      <td>0.996</td>\n      <td>0.026746</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LogisticRegressionCV</td>\n      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n      <td>0.998182</td>\n      <td>0.996</td>\n      <td>1.257428</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n      <td>1.000000</td>\n      <td>0.992</td>\n      <td>0.045213</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n      <td>1.000000</td>\n      <td>0.992</td>\n      <td>0.522662</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.992</td>\n      <td>0.020637</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n      <td>1.000000</td>\n      <td>0.992</td>\n      <td>0.268748</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GaussianNB</td>\n      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n      <td>0.997273</td>\n      <td>0.992</td>\n      <td>0.025370</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingClassifier</td>\n      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n      <td>1.000000</td>\n      <td>0.990</td>\n      <td>0.280876</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.995455</td>\n      <td>0.988</td>\n      <td>0.058963</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.981818</td>\n      <td>0.986</td>\n      <td>0.027319</td>\n      <td>[[25, 0], [25, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.997273</td>\n      <td>0.980</td>\n      <td>0.031632</td>\n      <td>[[25, 0], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.968</td>\n      <td>0.020701</td>\n      <td>[[24, 1], [0, 25]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\niris = sns.load_dataset(\"iris\")\nX = iris.iloc[:, :-1]\ny = iris.iloc[:, -1]\n\ncc = Classifier_comparision(X, y, test_size = 0.25, train_size = 0.6)\n%time cc.make_result()","execution_count":11,"outputs":[{"output_type":"stream","text":"CPU times: user 25.2 s, sys: 3.05 s, total: 28.3 s\nWall time: 22.8 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"                   MLA_model_name  \\\n14                            SVC   \n22     LinearDiscriminantAnalysis   \n16                            SVC   \n23  QuadraticDiscriminantAnalysis   \n13           KNeighborsClassifier   \n12                     GaussianNB   \n5       GaussianProcessClassifier   \n2            ExtraTreesClassifier   \n1               BaggingClassifier   \n6            LogisticRegressionCV   \n4          RandomForestClassifier   \n3      GradientBoostingClassifier   \n20         DecisionTreeClassifier   \n24                  XGBClassifier   \n0              AdaBoostClassifier   \n18                          NuSVC   \n19                      LinearSVC   \n15                            SVC   \n21            ExtraTreeClassifier   \n9                   SGDClassifier   \n8               RidgeClassifierCV   \n7     PassiveAggressiveClassifier   \n10                     Perceptron   \n11                    BernoulliNB   \n17                            SVC   \n\n                                          best_params  train_acc_kfold  \\\n14  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.984146   \n22  {'covariance_estimator': None, 'n_components':...         0.981707   \n16  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.987805   \n23  {'priors': None, 'reg_param': 0.0, 'store_cova...         0.985366   \n13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...         0.976829   \n12           {'priors': None, 'var_smoothing': 1e-09}         0.960976   \n5   {'copy_X_train': True, 'kernel': None, 'max_it...         0.971951   \n2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...         1.000000   \n1   {'base_estimator': None, 'bootstrap': True, 'b...         0.995122   \n6   {'Cs': 10, 'class_weight': None, 'cv': None, '...         0.979268   \n4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...         1.000000   \n3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...         1.000000   \n20  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n24  {'objective': 'binary:logistic', 'use_label_en...         1.000000   \n0   {'algorithm': 'SAMME.R', 'base_estimator': Non...         0.987805   \n18  {'break_ties': False, 'cache_size': 200, 'clas...         0.965854   \n19  {'C': 1.0, 'class_weight': None, 'dual': True,...         0.963415   \n15  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.997561   \n21  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n9   {'alpha': 0.0001, 'average': False, 'class_wei...         0.815854   \n8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...         0.879268   \n7   {'C': 1.0, 'average': False, 'class_weight': N...         0.831707   \n10  {'alpha': 0.0001, 'class_weight': None, 'early...         0.708537   \n11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...         0.374390   \n17  {'C': 1.0, 'break_ties': False, 'cache_size': ...         0.348780   \n\n    test_acc_kfold  run_time                      conf_test_matrix  \\\n14        0.978947  0.079365  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n22        0.978947  0.079049  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n16        0.976316  0.090394  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n23        0.976316  0.076614  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n13        0.963158  0.145267  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n12        0.957895  0.079128  [[13, 0, 0], [0, 13, 0], [0, 1, 11]]   \n5         0.957895  1.417088  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n2         0.955263  1.520717  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n1         0.955263  0.355397  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n6         0.955263  9.195157  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n4         0.955263  2.031607  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n3         0.952632  2.464967  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n20        0.952632  0.066057   [[13, 0, 0], [0, 12, 1], [0, 3, 9]]   \n24        0.952632  0.527342  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n0         0.952632  1.170062  [[13, 0, 0], [0, 12, 1], [0, 2, 10]]   \n18        0.952632  0.097347  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n19        0.947368  0.115158  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n15        0.942105  0.163908  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n21        0.926316  0.066170  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n9         0.815789  0.103466  [[13, 0, 0], [10, 0, 3], [0, 0, 12]]   \n8         0.802632  0.098613   [[13, 0, 0], [0, 8, 5], [0, 1, 11]]   \n7         0.789474  0.106452  [[13, 0, 0], [2, 10, 1], [0, 0, 12]]   \n10        0.686842  0.106927  [[13, 0, 0], [2, 10, 1], [0, 0, 12]]   \n11        0.294737  0.081437  [[0, 0, 13], [0, 0, 13], [0, 0, 12]]   \n17        0.281579  0.113579  [[0, 0, 13], [0, 0, 13], [0, 0, 12]]   \n\n                                      clf_test_report  \n14                precision    recall  f1-score   ...  \n22                precision    recall  f1-score   ...  \n16                precision    recall  f1-score   ...  \n23                precision    recall  f1-score   ...  \n13                precision    recall  f1-score   ...  \n12                precision    recall  f1-score   ...  \n5                 precision    recall  f1-score   ...  \n2                 precision    recall  f1-score   ...  \n1                 precision    recall  f1-score   ...  \n6                 precision    recall  f1-score   ...  \n4                 precision    recall  f1-score   ...  \n3                 precision    recall  f1-score   ...  \n20                precision    recall  f1-score   ...  \n24                precision    recall  f1-score   ...  \n0                 precision    recall  f1-score   ...  \n18                precision    recall  f1-score   ...  \n19                precision    recall  f1-score   ...  \n15                precision    recall  f1-score   ...  \n21                precision    recall  f1-score   ...  \n9                 precision    recall  f1-score   ...  \n8                 precision    recall  f1-score   ...  \n7                 precision    recall  f1-score   ...  \n10                precision    recall  f1-score   ...  \n11                precision    recall  f1-score   ...  \n17                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>14</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.984146</td>\n      <td>0.978947</td>\n      <td>0.079365</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>{'covariance_estimator': None, 'n_components':...</td>\n      <td>0.981707</td>\n      <td>0.978947</td>\n      <td>0.079049</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.987805</td>\n      <td>0.976316</td>\n      <td>0.090394</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>QuadraticDiscriminantAnalysis</td>\n      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n      <td>0.985366</td>\n      <td>0.976316</td>\n      <td>0.076614</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsClassifier</td>\n      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n      <td>0.976829</td>\n      <td>0.963158</td>\n      <td>0.145267</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GaussianNB</td>\n      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n      <td>0.960976</td>\n      <td>0.957895</td>\n      <td>0.079128</td>\n      <td>[[13, 0, 0], [0, 13, 0], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GaussianProcessClassifier</td>\n      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n      <td>0.971951</td>\n      <td>0.957895</td>\n      <td>1.417088</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesClassifier</td>\n      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n      <td>1.000000</td>\n      <td>0.955263</td>\n      <td>1.520717</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingClassifier</td>\n      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n      <td>0.995122</td>\n      <td>0.955263</td>\n      <td>0.355397</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LogisticRegressionCV</td>\n      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n      <td>0.979268</td>\n      <td>0.955263</td>\n      <td>9.195157</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n      <td>1.000000</td>\n      <td>0.955263</td>\n      <td>2.031607</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n      <td>1.000000</td>\n      <td>0.952632</td>\n      <td>2.464967</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.952632</td>\n      <td>0.066057</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 3, 9]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n      <td>1.000000</td>\n      <td>0.952632</td>\n      <td>0.527342</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n      <td>0.987805</td>\n      <td>0.952632</td>\n      <td>1.170062</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 2, 10]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NuSVC</td>\n      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n      <td>0.965854</td>\n      <td>0.952632</td>\n      <td>0.097347</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LinearSVC</td>\n      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n      <td>0.963415</td>\n      <td>0.947368</td>\n      <td>0.115158</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.997561</td>\n      <td>0.942105</td>\n      <td>0.163908</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.926316</td>\n      <td>0.066170</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SGDClassifier</td>\n      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n      <td>0.815854</td>\n      <td>0.815789</td>\n      <td>0.103466</td>\n      <td>[[13, 0, 0], [10, 0, 3], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeClassifierCV</td>\n      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n      <td>0.879268</td>\n      <td>0.802632</td>\n      <td>0.098613</td>\n      <td>[[13, 0, 0], [0, 8, 5], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PassiveAggressiveClassifier</td>\n      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n      <td>0.831707</td>\n      <td>0.789474</td>\n      <td>0.106452</td>\n      <td>[[13, 0, 0], [2, 10, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Perceptron</td>\n      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n      <td>0.708537</td>\n      <td>0.686842</td>\n      <td>0.106927</td>\n      <td>[[13, 0, 0], [2, 10, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.374390</td>\n      <td>0.294737</td>\n      <td>0.081437</td>\n      <td>[[0, 0, 13], [0, 0, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC</td>\n      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n      <td>0.348780</td>\n      <td>0.281579</td>\n      <td>0.113579</td>\n      <td>[[0, 0, 13], [0, 0, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"iris_bin = pd.DataFrame({})\nfor idx, fea_name in enumerate(iris.columns[: - 1]):\n    iris_bin[fea_name] = pd.qcut(iris.iloc[:, idx], 3, labels = False)\nX_bins = iris_bin.to_numpy()\n\ncc2 = Classifier_comparision(X_bins, y, test_size = 0.25, train_size = 0.6)\n%time res = cc2.make_result()\nres[res.MLA_model_name == 'BernoulliNB']","execution_count":12,"outputs":[{"output_type":"stream","text":"CPU times: user 16.8 s, sys: 1.3 s, total: 18.1 s\nWall time: 14.8 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"   MLA_model_name                                        best_params  \\\n11    BernoulliNB  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...   \n\n    train_acc_kfold  test_acc_kfold  run_time  \\\n11         0.776829        0.734211  0.030183   \n\n                        conf_test_matrix  \\\n11  [[0, 0, 13], [0, 0, 13], [0, 0, 12]]   \n\n                                      clf_test_report  \n11                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.776829</td>\n      <td>0.734211</td>\n      <td>0.030183</td>\n      <td>[[0, 0, 13], [0, 0, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"rate = 0.99\npca = PCA(rate)\nX = iris.iloc[:, :-1]\ny = iris.iloc[:, -1]\nX_pca = pca.fit_transform(X)\nn1 = X.shape[1]\nn2 = X_pca.shape[1]\nprint(\"{} is the number of dimension that keep {}% information from the original dataset {}.\"\n      .format(n2, int(rate*100), n1))\nprint(25*\"=\")\ncc_pca = Classifier_comparision(X_pca, y, test_size = 0.25, train_size = 0.6)\n%time cc_pca.make_result()","execution_count":13,"outputs":[{"output_type":"stream","text":"3 is the number of dimension that keep 99% information from the original dataset 4.\n=========================\nCPU times: user 16.4 s, sys: 1.27 s, total: 17.6 s\nWall time: 14.4 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"                   MLA_model_name  \\\n22     LinearDiscriminantAnalysis   \n14                            SVC   \n16                            SVC   \n23  QuadraticDiscriminantAnalysis   \n6            LogisticRegressionCV   \n13           KNeighborsClassifier   \n5       GaussianProcessClassifier   \n15                            SVC   \n18                          NuSVC   \n24                  XGBClassifier   \n2            ExtraTreesClassifier   \n1               BaggingClassifier   \n3      GradientBoostingClassifier   \n19                      LinearSVC   \n4          RandomForestClassifier   \n20         DecisionTreeClassifier   \n0              AdaBoostClassifier   \n12                     GaussianNB   \n17                            SVC   \n9                   SGDClassifier   \n10                     Perceptron   \n21            ExtraTreeClassifier   \n7     PassiveAggressiveClassifier   \n8               RidgeClassifierCV   \n11                    BernoulliNB   \n\n                                          best_params  train_acc_kfold  \\\n22  {'covariance_estimator': None, 'n_components':...         0.985366   \n14  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.984146   \n16  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.986585   \n23  {'priors': None, 'reg_param': 0.0, 'store_cova...         0.979268   \n6   {'Cs': 10, 'class_weight': None, 'cv': None, '...         0.979268   \n13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...         0.974390   \n5   {'copy_X_train': True, 'kernel': None, 'max_it...         0.971951   \n15  {'C': 1, 'break_ties': False, 'cache_size': 20...         0.984146   \n18  {'break_ties': False, 'cache_size': 200, 'clas...         0.963415   \n24  {'objective': 'binary:logistic', 'use_label_en...         1.000000   \n2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...         1.000000   \n1   {'base_estimator': None, 'bootstrap': True, 'b...         0.997561   \n3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...         1.000000   \n19  {'C': 1.0, 'class_weight': None, 'dual': True,...         0.959756   \n4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...         1.000000   \n20  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n0   {'algorithm': 'SAMME.R', 'base_estimator': Non...         0.962195   \n12           {'priors': None, 'var_smoothing': 1e-09}         0.939024   \n17  {'C': 1.0, 'break_ties': False, 'cache_size': ...         0.880488   \n9   {'alpha': 0.0001, 'average': False, 'class_wei...         0.920732   \n10  {'alpha': 0.0001, 'class_weight': None, 'early...         0.874390   \n21  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n7   {'C': 1.0, 'average': False, 'class_weight': N...         0.845122   \n8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...         0.873171   \n11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...         0.739024   \n\n    test_acc_kfold  run_time                      conf_test_matrix  \\\n22        0.989474  0.028625  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n14        0.981579  0.033138  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n16        0.973684  0.045023  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n23        0.965789  0.026767  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n6         0.960526  3.177977  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n13        0.960526  0.090272  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n5         0.957895  0.411074  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n15        0.952632  0.031242  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n18        0.952632  0.053935  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n24        0.944737  0.520984  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n2         0.942105  1.475745  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n1         0.936842  0.292157  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n3         0.931579  2.521876  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n19        0.928947  0.032145  [[13, 0, 0], [0, 12, 1], [0, 0, 12]]   \n4         0.926316  2.000243  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n20        0.926316  0.022443  [[13, 0, 0], [0, 12, 1], [0, 1, 11]]   \n0         0.915789  1.202208  [[13, 0, 0], [0, 12, 1], [0, 2, 10]]   \n12        0.889474  0.029565  [[13, 0, 0], [0, 13, 0], [0, 1, 11]]   \n17        0.886842  0.041672  [[0, 0, 13], [0, 0, 13], [0, 0, 12]]   \n9         0.876316  0.050858  [[13, 0, 0], [0, 13, 0], [0, 10, 2]]   \n10        0.834211  0.055212  [[13, 0, 0], [2, 10, 1], [0, 0, 12]]   \n21        0.815789  0.022103  [[13, 0, 0], [0, 12, 1], [0, 2, 10]]   \n7         0.807895  0.050850   [[13, 0, 0], [2, 6, 5], [0, 0, 12]]   \n8         0.794737  0.045384   [[13, 0, 0], [0, 8, 5], [0, 1, 11]]   \n11        0.702632  0.031084  [[0, 0, 13], [0, 0, 13], [0, 0, 12]]   \n\n                                      clf_test_report  \n22                precision    recall  f1-score   ...  \n14                precision    recall  f1-score   ...  \n16                precision    recall  f1-score   ...  \n23                precision    recall  f1-score   ...  \n6                 precision    recall  f1-score   ...  \n13                precision    recall  f1-score   ...  \n5                 precision    recall  f1-score   ...  \n15                precision    recall  f1-score   ...  \n18                precision    recall  f1-score   ...  \n24                precision    recall  f1-score   ...  \n2                 precision    recall  f1-score   ...  \n1                 precision    recall  f1-score   ...  \n3                 precision    recall  f1-score   ...  \n19                precision    recall  f1-score   ...  \n4                 precision    recall  f1-score   ...  \n20                precision    recall  f1-score   ...  \n0                 precision    recall  f1-score   ...  \n12                precision    recall  f1-score   ...  \n17                precision    recall  f1-score   ...  \n9                 precision    recall  f1-score   ...  \n10                precision    recall  f1-score   ...  \n21                precision    recall  f1-score   ...  \n7                 precision    recall  f1-score   ...  \n8                 precision    recall  f1-score   ...  \n11                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>22</th>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>{'covariance_estimator': None, 'n_components':...</td>\n      <td>0.985366</td>\n      <td>0.989474</td>\n      <td>0.028625</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.984146</td>\n      <td>0.981579</td>\n      <td>0.033138</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.986585</td>\n      <td>0.973684</td>\n      <td>0.045023</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>QuadraticDiscriminantAnalysis</td>\n      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n      <td>0.979268</td>\n      <td>0.965789</td>\n      <td>0.026767</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LogisticRegressionCV</td>\n      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n      <td>0.979268</td>\n      <td>0.960526</td>\n      <td>3.177977</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsClassifier</td>\n      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n      <td>0.974390</td>\n      <td>0.960526</td>\n      <td>0.090272</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GaussianProcessClassifier</td>\n      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n      <td>0.971951</td>\n      <td>0.957895</td>\n      <td>0.411074</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>0.984146</td>\n      <td>0.952632</td>\n      <td>0.031242</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NuSVC</td>\n      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n      <td>0.963415</td>\n      <td>0.952632</td>\n      <td>0.053935</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n      <td>1.000000</td>\n      <td>0.944737</td>\n      <td>0.520984</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesClassifier</td>\n      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n      <td>1.000000</td>\n      <td>0.942105</td>\n      <td>1.475745</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingClassifier</td>\n      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n      <td>0.997561</td>\n      <td>0.936842</td>\n      <td>0.292157</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n      <td>1.000000</td>\n      <td>0.931579</td>\n      <td>2.521876</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LinearSVC</td>\n      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n      <td>0.959756</td>\n      <td>0.928947</td>\n      <td>0.032145</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n      <td>1.000000</td>\n      <td>0.926316</td>\n      <td>2.000243</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.926316</td>\n      <td>0.022443</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n      <td>0.962195</td>\n      <td>0.915789</td>\n      <td>1.202208</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 2, 10]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GaussianNB</td>\n      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n      <td>0.939024</td>\n      <td>0.889474</td>\n      <td>0.029565</td>\n      <td>[[13, 0, 0], [0, 13, 0], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC</td>\n      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n      <td>0.880488</td>\n      <td>0.886842</td>\n      <td>0.041672</td>\n      <td>[[0, 0, 13], [0, 0, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SGDClassifier</td>\n      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n      <td>0.920732</td>\n      <td>0.876316</td>\n      <td>0.050858</td>\n      <td>[[13, 0, 0], [0, 13, 0], [0, 10, 2]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Perceptron</td>\n      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n      <td>0.874390</td>\n      <td>0.834211</td>\n      <td>0.055212</td>\n      <td>[[13, 0, 0], [2, 10, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.815789</td>\n      <td>0.022103</td>\n      <td>[[13, 0, 0], [0, 12, 1], [0, 2, 10]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PassiveAggressiveClassifier</td>\n      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n      <td>0.845122</td>\n      <td>0.807895</td>\n      <td>0.050850</td>\n      <td>[[13, 0, 0], [2, 6, 5], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>RidgeClassifierCV</td>\n      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n      <td>0.873171</td>\n      <td>0.794737</td>\n      <td>0.045384</td>\n      <td>[[13, 0, 0], [0, 8, 5], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.739024</td>\n      <td>0.702632</td>\n      <td>0.031084</td>\n      <td>[[0, 0, 13], [0, 0, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttn_df = sns.load_dataset(\"titanic\")\nttn_df.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"   survived  pclass     sex   age  sibsp  parch     fare embarked  class  \\\n0         0       3    male  22.0      1      0   7.2500        S  Third   \n1         1       1  female  38.0      1      0  71.2833        C  First   \n2         1       3  female  26.0      0      0   7.9250        S  Third   \n3         1       1  female  35.0      1      0  53.1000        S  First   \n4         0       3    male  35.0      0      0   8.0500        S  Third   \n\n     who  adult_male deck  embark_town alive  alone  \n0    man        True  NaN  Southampton    no  False  \n1  woman       False    C    Cherbourg   yes  False  \n2  woman       False  NaN  Southampton   yes   True  \n3  woman       False    C  Southampton   yes  False  \n4    man        True  NaN  Southampton    no   True  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>survived</th>\n      <th>pclass</th>\n      <th>sex</th>\n      <th>age</th>\n      <th>sibsp</th>\n      <th>parch</th>\n      <th>fare</th>\n      <th>embarked</th>\n      <th>class</th>\n      <th>who</th>\n      <th>adult_male</th>\n      <th>deck</th>\n      <th>embark_town</th>\n      <th>alive</th>\n      <th>alone</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>7.2500</td>\n      <td>S</td>\n      <td>Third</td>\n      <td>man</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n      <td>no</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>71.2833</td>\n      <td>C</td>\n      <td>First</td>\n      <td>woman</td>\n      <td>False</td>\n      <td>C</td>\n      <td>Cherbourg</td>\n      <td>yes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7.9250</td>\n      <td>S</td>\n      <td>Third</td>\n      <td>woman</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n      <td>yes</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>1</td>\n      <td>female</td>\n      <td>35.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>53.1000</td>\n      <td>S</td>\n      <td>First</td>\n      <td>woman</td>\n      <td>False</td>\n      <td>C</td>\n      <td>Southampton</td>\n      <td>yes</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>3</td>\n      <td>male</td>\n      <td>35.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.0500</td>\n      <td>S</td>\n      <td>Third</td>\n      <td>man</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>Southampton</td>\n      <td>no</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ttn_dum2 = ttn_df.drop(columns = ['alive'])\n#ttn_dum2['age'] = pd.qcut(ttn_dum2['age'], 4, labels=[\"children\", \"teen\", \"alduts\", \"old\"])\n#ttn_dum2['fare'] = pd.qcut(ttn_dum2['fare'], 3, labels=[\"cheap\", \"medium\", \"expensive\"])\nttn_dum2 = pd.get_dummies(ttn_dum2)\nttn_dum2 = ttn_dum2.astype('float64')\nttn_dum2 = ttn_dum2.fillna(0)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ttn_dum2.iloc[:, 1:]\ny = ttn_dum2.iloc[:, 0]\ncc = Classifier_comparision(X, y, test_size = 0.25, train_size = 0.6)\n%time cc.make_result()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. For `wine` dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import datasets\n#Load dataset\nwine = datasets.load_wine()\nX = wine['data']\ny = wine['target']\n\ncc2 = Classifier_comparision(X, y, test_size = 0.25, train_size = 0.6)\n%time res = cc2.make_result()\nres","execution_count":19,"outputs":[{"output_type":"stream","text":"CPU times: user 36.6 s, sys: 1.19 s, total: 37.8 s\nWall time: 34.6 s\n","name":"stdout"},{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"                   MLA_model_name  \\\n8               RidgeClassifierCV   \n2            ExtraTreesClassifier   \n22     LinearDiscriminantAnalysis   \n4          RandomForestClassifier   \n23  QuadraticDiscriminantAnalysis   \n12                     GaussianNB   \n24                  XGBClassifier   \n6            LogisticRegressionCV   \n1               BaggingClassifier   \n15                            SVC   \n14                            SVC   \n3      GradientBoostingClassifier   \n0              AdaBoostClassifier   \n20         DecisionTreeClassifier   \n21            ExtraTreeClassifier   \n18                          NuSVC   \n19                      LinearSVC   \n13           KNeighborsClassifier   \n7     PassiveAggressiveClassifier   \n9                   SGDClassifier   \n10                     Perceptron   \n5       GaussianProcessClassifier   \n16                            SVC   \n11                    BernoulliNB   \n17                            SVC   \n\n                                          best_params  train_acc_kfold  \\\n8   {'alphas': array([ 0.1,  1. , 10. ]), 'class_w...         0.997938   \n2   {'bootstrap': False, 'ccp_alpha': 0.0, 'class_...         1.000000   \n22  {'covariance_estimator': None, 'n_components':...         0.998969   \n4   {'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...         1.000000   \n23  {'priors': None, 'reg_param': 0.0, 'store_cova...         1.000000   \n12           {'priors': None, 'var_smoothing': 1e-09}         0.989691   \n24  {'objective': 'binary:logistic', 'use_label_en...         1.000000   \n6   {'Cs': 10, 'class_weight': None, 'cv': None, '...         0.993814   \n1   {'base_estimator': None, 'bootstrap': True, 'b...         0.997938   \n15  {'C': 1, 'break_ties': False, 'cache_size': 20...         1.000000   \n14  {'C': 1, 'break_ties': False, 'cache_size': 20...         1.000000   \n3   {'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...         1.000000   \n0   {'algorithm': 'SAMME.R', 'base_estimator': Non...         0.979381   \n20  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n21  {'ccp_alpha': 0.0, 'class_weight': None, 'crit...         1.000000   \n18  {'break_ties': False, 'cache_size': 200, 'clas...         0.851546   \n19  {'C': 1.0, 'class_weight': None, 'dual': True,...         0.817526   \n13  {'algorithm': 'auto', 'leaf_size': 30, 'metric...         0.792784   \n7   {'C': 1.0, 'average': False, 'class_weight': N...         0.598969   \n9   {'alpha': 0.0001, 'average': False, 'class_wei...         0.542268   \n10  {'alpha': 0.0001, 'class_weight': None, 'early...         0.554639   \n5   {'copy_X_train': True, 'kernel': None, 'max_it...         1.000000   \n16  {'C': 1, 'break_ties': False, 'cache_size': 20...         1.000000   \n11  {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...         0.400000   \n17  {'C': 1.0, 'break_ties': False, 'cache_size': ...         0.293814   \n\n    test_acc_kfold   run_time                      conf_test_matrix  \\\n8         0.977778   0.037742  [[15, 0, 0], [0, 17, 1], [0, 0, 12]]   \n2         0.975556   1.491599  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n22        0.973333   0.023303  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n4         0.966667   2.033749  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n23        0.966667   0.023784  [[15, 0, 0], [0, 18, 0], [0, 1, 11]]   \n12        0.962222   0.022540  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n24        0.946667   0.501597  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n6         0.937778  14.155421  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n1         0.935556   0.406410  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n15        0.928889   3.379251  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n14        0.926667   2.648293  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n3         0.911111   3.187459  [[15, 0, 0], [0, 18, 0], [0, 0, 12]]   \n0         0.908889   1.116765  [[14, 1, 0], [0, 17, 1], [0, 0, 12]]   \n20        0.906667   0.019237  [[14, 1, 0], [1, 17, 0], [0, 1, 11]]   \n21        0.846667   0.016248  [[13, 2, 0], [1, 16, 1], [0, 0, 12]]   \n18        0.831111   0.067241  [[14, 1, 0], [0, 18, 0], [2, 0, 10]]   \n19        0.793333   0.152637   [[11, 4, 0], [0, 18, 0], [0, 5, 7]]   \n13        0.673333   0.090940   [[14, 0, 1], [0, 10, 8], [2, 3, 7]]   \n7         0.608889   0.045309  [[11, 4, 0], [0, 18, 0], [0, 12, 0]]   \n9         0.562222   0.043591    [[15, 0, 0], [7, 3, 8], [7, 0, 5]]   \n10        0.560000   0.043099  [[2, 13, 0], [0, 18, 0], [0, 12, 0]]   \n5         0.433333   0.397961  [[3, 0, 12], [0, 5, 13], [0, 0, 12]]   \n16        0.373333   0.081342  [[0, 15, 0], [0, 18, 0], [0, 12, 0]]   \n11        0.373333   0.021852  [[0, 15, 0], [0, 18, 0], [0, 12, 0]]   \n17        0.253333   0.087791  [[0, 15, 0], [12, 6, 0], [10, 2, 0]]   \n\n                                      clf_test_report  \n8                 precision    recall  f1-score   ...  \n2                 precision    recall  f1-score   ...  \n22                precision    recall  f1-score   ...  \n4                 precision    recall  f1-score   ...  \n23                precision    recall  f1-score   ...  \n12                precision    recall  f1-score   ...  \n24                precision    recall  f1-score   ...  \n6                 precision    recall  f1-score   ...  \n1                 precision    recall  f1-score   ...  \n15                precision    recall  f1-score   ...  \n14                precision    recall  f1-score   ...  \n3                 precision    recall  f1-score   ...  \n0                 precision    recall  f1-score   ...  \n20                precision    recall  f1-score   ...  \n21                precision    recall  f1-score   ...  \n18                precision    recall  f1-score   ...  \n19                precision    recall  f1-score   ...  \n13                precision    recall  f1-score   ...  \n7                 precision    recall  f1-score   ...  \n9                 precision    recall  f1-score   ...  \n10                precision    recall  f1-score   ...  \n5                 precision    recall  f1-score   ...  \n16                precision    recall  f1-score   ...  \n11                precision    recall  f1-score   ...  \n17                precision    recall  f1-score   ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>MLA_model_name</th>\n      <th>best_params</th>\n      <th>train_acc_kfold</th>\n      <th>test_acc_kfold</th>\n      <th>run_time</th>\n      <th>conf_test_matrix</th>\n      <th>clf_test_report</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>8</th>\n      <td>RidgeClassifierCV</td>\n      <td>{'alphas': array([ 0.1,  1. , 10. ]), 'class_w...</td>\n      <td>0.997938</td>\n      <td>0.977778</td>\n      <td>0.037742</td>\n      <td>[[15, 0, 0], [0, 17, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ExtraTreesClassifier</td>\n      <td>{'bootstrap': False, 'ccp_alpha': 0.0, 'class_...</td>\n      <td>1.000000</td>\n      <td>0.975556</td>\n      <td>1.491599</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>LinearDiscriminantAnalysis</td>\n      <td>{'covariance_estimator': None, 'n_components':...</td>\n      <td>0.998969</td>\n      <td>0.973333</td>\n      <td>0.023303</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>RandomForestClassifier</td>\n      <td>{'bootstrap': True, 'ccp_alpha': 0.0, 'class_w...</td>\n      <td>1.000000</td>\n      <td>0.966667</td>\n      <td>2.033749</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>QuadraticDiscriminantAnalysis</td>\n      <td>{'priors': None, 'reg_param': 0.0, 'store_cova...</td>\n      <td>1.000000</td>\n      <td>0.966667</td>\n      <td>0.023784</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>GaussianNB</td>\n      <td>{'priors': None, 'var_smoothing': 1e-09}</td>\n      <td>0.989691</td>\n      <td>0.962222</td>\n      <td>0.022540</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>XGBClassifier</td>\n      <td>{'objective': 'binary:logistic', 'use_label_en...</td>\n      <td>1.000000</td>\n      <td>0.946667</td>\n      <td>0.501597</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>LogisticRegressionCV</td>\n      <td>{'Cs': 10, 'class_weight': None, 'cv': None, '...</td>\n      <td>0.993814</td>\n      <td>0.937778</td>\n      <td>14.155421</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>BaggingClassifier</td>\n      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n      <td>0.997938</td>\n      <td>0.935556</td>\n      <td>0.406410</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>1.000000</td>\n      <td>0.928889</td>\n      <td>3.379251</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>1.000000</td>\n      <td>0.926667</td>\n      <td>2.648293</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>GradientBoostingClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'criterion': 'friedman_mse'...</td>\n      <td>1.000000</td>\n      <td>0.911111</td>\n      <td>3.187459</td>\n      <td>[[15, 0, 0], [0, 18, 0], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>AdaBoostClassifier</td>\n      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n      <td>0.979381</td>\n      <td>0.908889</td>\n      <td>1.116765</td>\n      <td>[[14, 1, 0], [0, 17, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>DecisionTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.906667</td>\n      <td>0.019237</td>\n      <td>[[14, 1, 0], [1, 17, 0], [0, 1, 11]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>ExtraTreeClassifier</td>\n      <td>{'ccp_alpha': 0.0, 'class_weight': None, 'crit...</td>\n      <td>1.000000</td>\n      <td>0.846667</td>\n      <td>0.016248</td>\n      <td>[[13, 2, 0], [1, 16, 1], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>NuSVC</td>\n      <td>{'break_ties': False, 'cache_size': 200, 'clas...</td>\n      <td>0.851546</td>\n      <td>0.831111</td>\n      <td>0.067241</td>\n      <td>[[14, 1, 0], [0, 18, 0], [2, 0, 10]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>LinearSVC</td>\n      <td>{'C': 1.0, 'class_weight': None, 'dual': True,...</td>\n      <td>0.817526</td>\n      <td>0.793333</td>\n      <td>0.152637</td>\n      <td>[[11, 4, 0], [0, 18, 0], [0, 5, 7]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>KNeighborsClassifier</td>\n      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n      <td>0.792784</td>\n      <td>0.673333</td>\n      <td>0.090940</td>\n      <td>[[14, 0, 1], [0, 10, 8], [2, 3, 7]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>PassiveAggressiveClassifier</td>\n      <td>{'C': 1.0, 'average': False, 'class_weight': N...</td>\n      <td>0.598969</td>\n      <td>0.608889</td>\n      <td>0.045309</td>\n      <td>[[11, 4, 0], [0, 18, 0], [0, 12, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>SGDClassifier</td>\n      <td>{'alpha': 0.0001, 'average': False, 'class_wei...</td>\n      <td>0.542268</td>\n      <td>0.562222</td>\n      <td>0.043591</td>\n      <td>[[15, 0, 0], [7, 3, 8], [7, 0, 5]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>Perceptron</td>\n      <td>{'alpha': 0.0001, 'class_weight': None, 'early...</td>\n      <td>0.554639</td>\n      <td>0.560000</td>\n      <td>0.043099</td>\n      <td>[[2, 13, 0], [0, 18, 0], [0, 12, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>GaussianProcessClassifier</td>\n      <td>{'copy_X_train': True, 'kernel': None, 'max_it...</td>\n      <td>1.000000</td>\n      <td>0.433333</td>\n      <td>0.397961</td>\n      <td>[[3, 0, 12], [0, 5, 13], [0, 0, 12]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>SVC</td>\n      <td>{'C': 1, 'break_ties': False, 'cache_size': 20...</td>\n      <td>1.000000</td>\n      <td>0.373333</td>\n      <td>0.081342</td>\n      <td>[[0, 15, 0], [0, 18, 0], [0, 12, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>BernoulliNB</td>\n      <td>{'alpha': 1.0, 'binarize': 0.0, 'class_prior':...</td>\n      <td>0.400000</td>\n      <td>0.373333</td>\n      <td>0.021852</td>\n      <td>[[0, 15, 0], [0, 18, 0], [0, 12, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>SVC</td>\n      <td>{'C': 1.0, 'break_ties': False, 'cache_size': ...</td>\n      <td>0.293814</td>\n      <td>0.253333</td>\n      <td>0.087791</td>\n      <td>[[0, 15, 0], [12, 6, 0], [10, 2, 0]]</td>\n      <td>precision    recall  f1-score   ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Spam detection"},{"metadata":{"trusted":true},"cell_type":"code","source":"#mydataset = dataiku.Dataset(\"spam\")\n#spam_df = mydataset.get_dataframe()\nspam_df = pd.read_csv(r\"../input/nhandv6/spam.csv\", usecols = ['text_mes', 'target'], encoding='ISO-8859-1')\nspam_df = spam_df.iloc[1:, :2]\nspam_df.columns = ['target', 'text_mes']\nspam_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spam_sumr_ = pd.DataFrame({})\nspam_df = spam_df.drop_duplicates()\nspam_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import STOPWORDS\nimport string\n\nspam_sumr_['total_words'] = spam_df.text_mes.apply(lambda x: len(x.split()))\nspam_sumr_['total_unique_words'] = spam_df.text_mes.apply(lambda x: len(set(x.split())))\nspam_sumr_['char_count'] = spam_df.text_mes.apply(lambda x: len(x))\nspam_sumr_['average_words'] = (spam_sumr_.char_count / spam_sumr_.total_words).round(2)\nspam_sumr_['count_stopwords'] = spam_df.text_mes.apply(lambda x: len([w for w in str(x).lower().split() if w in STOPWORDS]))\nspam_sumr_['count_punct'] = spam_df.text_mes.apply(lambda x: len([w for w in str(x) if w in string.punctuation]))\nspam_sumr_['count_hashtag#'] = spam_df.text_mes.apply(lambda x: x.count('#'))\nspam_sumr_['count_fb.tag@'] = spam_df.text_mes.apply(lambda x: x.count('@'))\nspam_sumr_['count_url'] = spam_df.text_mes.apply(lambda x: len([w for w in str(x).lower() if 'http' in w or 'https' in w or 'www' in w]))\n\nspam_sumr_.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\ntext_process = CountVectorizer().fit_transform(spam_df['text_mes'])\ntfidf_vect = TfidfVectorizer()\ntfidf_X = tfidf_vect.fit_transform(spam_df['text_mes'])\ntfidf_X.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cate_X = spam_sumr_.iloc[:, ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = tfidf_X.toarray()\ny = spam_df['target']\n\ncc2 = Classifier_comparision(X, y, test_size = 0.25, train_size = 0.6)\n%time res = cc2.make_result()\nres","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}