{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is time i write a notebook for classification problem. \n\nI am looking forward to your considerations"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\ndataset = pd.read_csv(r'../input/social-network-ads/Social_Network_Ads.csv')\ndataset = dataset.set_index('User ID')\ndataset.head()","execution_count":102,"outputs":[{"output_type":"stream","text":"/kaggle/input/social-network-ads/Social_Network_Ads.csv\n","name":"stdout"},{"output_type":"execute_result","execution_count":102,"data":{"text/plain":"          Gender  Age  EstimatedSalary  Purchased\nUser ID                                          \n15624510    Male   19            19000          0\n15810944    Male   35            20000          0\n15668575  Female   26            43000          0\n15603246  Female   27            57000          0\n15804002    Male   19            76000          0","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Gender</th>\n      <th>Age</th>\n      <th>EstimatedSalary</th>\n      <th>Purchased</th>\n    </tr>\n    <tr>\n      <th>User ID</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>15624510</th>\n      <td>Male</td>\n      <td>19</td>\n      <td>19000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15810944</th>\n      <td>Male</td>\n      <td>35</td>\n      <td>20000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15668575</th>\n      <td>Female</td>\n      <td>26</td>\n      <td>43000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15603246</th>\n      <td>Female</td>\n      <td>27</td>\n      <td>57000</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>15804002</th>\n      <td>Male</td>\n      <td>19</td>\n      <td>76000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"The dataset contained the information of the customers, \n>     \"gender\" : categorical variable of 2 classes ['Male' & 'Female']\n>     \"age\" : continuous variable takes the values be the integers\n>     \"estimated_salary\" : continuous vrs \nand these \"features\" are indexed by `user_ID`. \n\nThe `label (\"Purchased\")` in this dataset is indexed by `{0 (None), 1 (Done)}`\n\n------------------------------------------\n\n## 1. Using `Logistic regression`\n\n### 1.1. Model with the last 2 feature which be the `continuous variables`\n\nFirst of all, assign the values of `data` by $X$ and `label` to $y$\nThen, look at the proportions of the label"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"X = dataset.iloc[:,-3:-1].values\ny = dataset.iloc[:, -1].values\nplt.hist(y);\nX.shape, y.shape, len(y[y==0]), len(y[y==1])","execution_count":103,"outputs":[{"output_type":"execute_result","execution_count":103,"data":{"text/plain":"((400, 2), (400,), 257, 143)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"We can see that there are 64% dataset has label = 0 (No purchased), so we must add the statement `stratify = y` in the `train_test_split()`\n\nFor example, if we take `test_size = 25%` then\n\n$$ \\dfrac{\\vert y_\\text{train} \\vert}{\\vert y_\\text{test} \\vert} \\approx \\dfrac{\\vert y_\\text{train} \\vert}{\\vert y_\\text{test} \\vert } \\approx 3 $$\n\nwhere $\\vert A \\vert$ denoted the cardinal number of the set $A$."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 33, stratify = y)\n\nplt.hist(y_train)\nplt.hist(y_test, stacked = True);\nlen(y_train[y_train == 0]) / len(y_test[y_test == 0]), len(y_train[y_train == 1]) / len(y_test[y_test == 1])","execution_count":104,"outputs":[{"output_type":"execute_result","execution_count":104,"data":{"text/plain":"(3.015625, 2.9722222222222223)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"#### Scaling the features"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train)\nX_test_sc = sc.transform(X_test)","execution_count":105,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fit the Logistic_regression model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train_sc, y_train)","execution_count":106,"outputs":[{"output_type":"execute_result","execution_count":106,"data":{"text/plain":"LogisticRegression(random_state=0)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Predict the values in the test_set then evaluate them"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = classifier.predict(X_test_sc)\nfrom sklearn.metrics import confusion_matrix, accuracy_score, f1_score\ncm = confusion_matrix(y_test, y_pred)\nprint('confusion matrix :\\n', cm)\nprint(\"Accuracy: \",accuracy_score(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"f1-score:\", f1)","execution_count":107,"outputs":[{"output_type":"stream","text":"confusion matrix :\n [[58  6]\n [ 7 29]]\nAccuracy:  0.87\nf1-score: 0.8169014084507044\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\ndef plot_roc_curve(fpr, tpr, label=None):\n    plt.plot(fpr, tpr, linewidth=2, label=label)\n    plt.plot([0, 1], [0, 1], 'o--')\n    plt.axis([0, 1, 0, 1])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\nplot_roc_curve(fpr, tpr)\nplt.show()","execution_count":108,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"### 1.2 Using Logistic Regression with full features in model\n\nFor the `categorical vrs (\"gender\")`, we can use `one-hot-encode` to assign it to `{0 (male), 1 (female) }`"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nX1 = dataset.iloc[:, 0:1].values\nenc = OneHotEncoder(handle_unknown='ignore')\nx1 = enc.fit_transform(X1).toarray().astype(int)\nx1[:3]","execution_count":109,"outputs":[{"output_type":"execute_result","execution_count":109,"data":{"text/plain":"array([[0, 1],\n       [0, 1],\n       [1, 0]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_full = np.concatenate((x1, X), axis=1)\nX_full[: 3]","execution_count":110,"outputs":[{"output_type":"execute_result","execution_count":110,"data":{"text/plain":"array([[    0,     1,    19, 19000],\n       [    0,     1,    35, 20000],\n       [    1,     0,    26, 43000]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Train-test-split dataset\n\nFollow that, `X_train_full = [ X_train_scale(continuous vrs), X_train_one-hot-encode ]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_full, y, test_size = 0.25, random_state = 33, stratify = y)\n\nsc = StandardScaler()\nX_train_sc = sc.fit_transform(X_train[:, 2:])\nX_test_sc = sc.transform(X_test[: ,2:])\nX_train_full = np.concatenate((X_train[:, :2], X_train_sc), axis=1)\nX_test_full = np.concatenate((X_test[:, :2], X_test_sc), axis=1)","execution_count":111,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fit the model & evaluate"},{"metadata":{"trusted":true},"cell_type":"code","source":"classifier = LogisticRegression(random_state = 33)\nclassifier.fit(X_train_full, y_train)\ny_pred = classifier.predict(X_test_full)\ncm = confusion_matrix(y_test, y_pred)\nprint('confusion matrix :\\n', cm)\nprint(\"Accuracy: \",accuracy_score(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"f1-score:\", f1)","execution_count":112,"outputs":[{"output_type":"stream","text":"confusion matrix :\n [[59  5]\n [ 6 30]]\nAccuracy:  0.89\nf1-score: 0.8450704225352113\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"### First summary in logistic regression.\n\n>  Using the last 2 features give \"accuracy\" is about 0.87 and \"f1-score\" is about 0.816\n> \n>  Using the full-features give \"accuracy\" is about 0.89 and \"f1-score\" is about 0.845 which is better than the previous.\n\n## 2. Using Naive-Bayes for the full-model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score as acc\n\nclf = GaussianNB()\nclf.fit(X_train_full, y_train)\ny_pred = clf.predict(X_test_full)\ncm = confusion_matrix(y_test, y_pred)\nprint('confusion matrix :\\n', cm)\nprint(\"Accuracy: \",accuracy_score(y_test, y_pred))\nf1 = f1_score(y_test, y_pred)\nprint(\"f1-score:\", f1)","execution_count":113,"outputs":[{"output_type":"stream","text":"confusion matrix :\n [[57  7]\n [ 4 32]]\nAccuracy:  0.89\nf1-score: 0.8533333333333333\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Hence, using `Gaussian Naive Bayes` model, we had improved the \"f1-score\" to 0.8533"},{"metadata":{},"cell_type":"markdown","source":"## 3. Using SVM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\nkernel_names = ['linear', 'poly', 'rbf', 'sigmoid']\nfor k in range(4):\n    print(' %4sSVM(kernel = \"%s\") \\n================================'%('', kernel_names[k]))\n    clf = SVC(kernel = kernel_names[k])\n    clf.fit(X_train_full, y_train)\n    y_pred_tr = clf.predict(X_train_full)\n    y_pred_ts = clf.predict(X_test_full)\n    cm = confusion_matrix(y_test, y_pred_ts)\n    print('confusion matrix :\\n', cm)\n    print(\"Training accuracy: %.4f\"%accuracy_score(y_train, y_pred_tr))\n    print(\"Testing accuracy: %.4f\"%accuracy_score(y_test, y_pred_ts))\n    f1 = f1_score(y_test, y_pred_ts)\n    print(\"f1-score: %.4f\"%f1)\n    print('================================')","execution_count":114,"outputs":[{"output_type":"stream","text":"     SVM(kernel = \"linear\") \n================================\nconfusion matrix :\n [[58  6]\n [11 25]]\nTraining accuracy: 0.8300\nTesting accuracy: 0.8300\nf1-score: 0.7463\n================================\n     SVM(kernel = \"poly\") \n================================\nconfusion matrix :\n [[58  6]\n [ 5 31]]\nTraining accuracy: 0.9033\nTesting accuracy: 0.8900\nf1-score: 0.8493\n================================\n     SVM(kernel = \"rbf\") \n================================\nconfusion matrix :\n [[57  7]\n [ 3 33]]\nTraining accuracy: 0.9133\nTesting accuracy: 0.9000\nf1-score: 0.8684\n================================\n     SVM(kernel = \"sigmoid\") \n================================\nconfusion matrix :\n [[52 12]\n [20 16]]\nTraining accuracy: 0.6533\nTesting accuracy: 0.6800\nf1-score: 0.5000\n================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"So, with `SVM(kernel = 'rbf')`, we improved the \"f1-score\" to `0.868`"},{"metadata":{},"cell_type":"markdown","source":"## 4. Using K-nn or `K-nearest neighbor`"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\n\nfor k in [2, 10, 20, 100]:\n    print('\\tUsing KNN with n_neighbors = %s \\n %5s =====================%5s'%(k,'', ''))\n    knn = KNeighborsClassifier(n_neighbors = k)\n    clf = knn.fit(X_train_full, y_train)\n    y_pred_tr = clf.predict(X_train_full)\n    y_pred_ts = clf.predict(X_test_full)\n    cm = confusion_matrix(y_test, y_pred_ts)\n    print('confusion matrix :\\n', cm)\n    print(\"Training accuracy: %.4f\"%accuracy_score(y_train, y_pred_tr))\n    print(\"Testing accuracy: %.4f\"%accuracy_score(y_test, y_pred_ts))\n    f1 = f1_score(y_test, y_pred_ts)\n    print(\"f1-score: %.4f\"%f1)\n    print('===============================================')","execution_count":115,"outputs":[{"output_type":"stream","text":"\tUsing KNN with n_neighbors = 2 \n       =====================     \nconfusion matrix :\n [[61  3]\n [ 7 29]]\nTraining accuracy: 0.9367\nTesting accuracy: 0.9000\nf1-score: 0.8529\n===============================================\n\tUsing KNN with n_neighbors = 10 \n       =====================     \nconfusion matrix :\n [[58  6]\n [ 3 33]]\nTraining accuracy: 0.9167\nTesting accuracy: 0.9100\nf1-score: 0.8800\n===============================================\n\tUsing KNN with n_neighbors = 20 \n       =====================     \nconfusion matrix :\n [[58  6]\n [ 5 31]]\nTraining accuracy: 0.9000\nTesting accuracy: 0.8900\nf1-score: 0.8493\n===============================================\n\tUsing KNN with n_neighbors = 100 \n       =====================     \nconfusion matrix :\n [[62  2]\n [21 15]]\nTraining accuracy: 0.7833\nTesting accuracy: 0.7700\nf1-score: 0.5660\n===============================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"In the `KNN with k = 10`, we obtain the higest \"f1-score\" = 0.88"},{"metadata":{},"cell_type":"markdown","source":"## 5. Using Adaboost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import TruncatedSVD\n\nfor lr in [0.1, 1, 10]:\n    for n_est in [10, 20, 30]:\n        print('AdaBoostClassifier(n_estimators = %s, learning_rate = %s)\\n %10s===================================%10s'%(n_est, lr, '', ''))\n        clf = AdaBoostClassifier(n_estimators = 30,\n                                 learning_rate = 1)\n        clf.fit(X_train_full, y_train)\n        y_pred = clf.predict(X_test)\n        y_pred_tr = clf.predict(X_train_full)\n        y_pred_ts = clf.predict(X_test_full)\n        cm = confusion_matrix(y_test, y_pred_ts)\n        print('confusion matrix :\\n', cm)\n        print(\"Training accuracy: %.4f\"%accuracy_score(y_train, y_pred_tr))\n        print(\"Testing accuracy: %.4f\"%accuracy_score(y_test, y_pred_ts))\n        f1 = f1_score(y_test, y_pred_ts)\n        print(\"f1-score: %.4f\"%f1)\n        print('==========================================================')","execution_count":116,"outputs":[{"output_type":"stream","text":"AdaBoostClassifier(n_estimators = 10, learning_rate = 0.1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 20, learning_rate = 0.1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 30, learning_rate = 0.1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 10, learning_rate = 1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 20, learning_rate = 1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 30, learning_rate = 1)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 10, learning_rate = 10)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 20, learning_rate = 10)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\nAdaBoostClassifier(n_estimators = 30, learning_rate = 10)\n           ===================================          \nconfusion matrix :\n [[58  6]\n [ 6 30]]\nTraining accuracy: 0.9200\nTesting accuracy: 0.8800\nf1-score: 0.8333\n==========================================================\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Using `AdaBoost`, we obtain the \"f1-score\" about 0.833 which is not better than using `SVM(kernel = 'rbf')` or `KNN(n_neighbors = 10)`"},{"metadata":{},"cell_type":"markdown","source":"## 6. Using XGBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBClassifier\n\nf1_scores = []\nfor dpt in [3, 5, 15, 30, 50]:\n    print('%8s XGBClassifier(max_depth = %s)\\n %5s===================================%5s'%('', dpt, '', ''))\n    clf = XGBClassifier(max_depth = dpt) \n    clf.fit(X_train_full, y_train, eval_metric=\"auc\")\n    y_pred = clf.predict(X_test)\n    y_pred_tr = clf.predict(X_train_full)\n    y_pred_ts = clf.predict(X_test_full)\n    cm = confusion_matrix(y_test, y_pred_ts)\n    print('confusion matrix :\\n', cm)\n    print(\"Training accuracy: %.4f\"%accuracy_score(y_train, y_pred_tr))\n    print(\"Testing accuracy: %.4f\"%accuracy_score(y_test, y_pred_ts))\n    f1 = f1_score(y_test, y_pred_ts)\n    print(\"f1-score: %.4f\"%f1)\n    print('==========================================================')\n    f1_scores.append(f1)\n    \nmax(f1_scores)","execution_count":117,"outputs":[{"output_type":"stream","text":"         XGBClassifier(max_depth = 3)\n      ===================================     \nconfusion matrix :\n [[57  7]\n [ 4 32]]\nTraining accuracy: 0.9667\nTesting accuracy: 0.8900\nf1-score: 0.8533\n==========================================================\n         XGBClassifier(max_depth = 5)\n      ===================================     \nconfusion matrix :\n [[57  7]\n [ 4 32]]\nTraining accuracy: 0.9867\nTesting accuracy: 0.8900\nf1-score: 0.8533\n==========================================================\n         XGBClassifier(max_depth = 15)\n      ===================================     \nconfusion matrix :\n [[57  7]\n [ 4 32]]\nTraining accuracy: 0.9867\nTesting accuracy: 0.8900\nf1-score: 0.8533\n==========================================================\n         XGBClassifier(max_depth = 30)\n      ===================================     \nconfusion matrix :\n [[57  7]\n [ 4 32]]\nTraining accuracy: 0.9867\nTesting accuracy: 0.8900\nf1-score: 0.8533\n==========================================================\n         XGBClassifier(max_depth = 50)\n      ===================================     \nconfusion matrix :\n [[57  7]\n [ 4 32]]\nTraining accuracy: 0.9867\nTesting accuracy: 0.8900\nf1-score: 0.8533\n==========================================================\n","name":"stdout"},{"output_type":"execute_result","execution_count":117,"data":{"text/plain":"0.8533333333333333"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"By using `XGBoost`, we obtain the \"f1-score\" is about 0.8533 which is not better than using `SVM(kernel = \"rbf\")` and `KNN(n_neighbors = 10)`."},{"metadata":{},"cell_type":"markdown","source":"## 7. Using Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\nf1_scores = []\nfor m_dpt in [2, 5, 10]:\n    for n_est in [20, 50, 100, 300]:\n        print('RandomForestClassifier(n_estimators = %s, max_depth = %s)\\n %10s===================================%10s'%(n_est, m_dpt, '', ''))\n        clf = RandomForestClassifier(max_depth = 3, n_estimators = 300)\n        clf.fit(X_train_full, y_train)\n        y_pred = clf.predict(X_test)\n        y_pred_tr = clf.predict(X_train_full)\n        y_pred_ts = clf.predict(X_test_full)\n        cm = confusion_matrix(y_test, y_pred_ts)\n        print('confusion matrix :\\n', cm)\n        print(\"Training accuracy: %.4f\"%accuracy_score(y_train, y_pred_tr))\n        print(\"Testing accuracy: %.4f\"%accuracy_score(y_test, y_pred_ts))\n        f1 = f1_score(y_test, y_pred_ts)\n        print(\"f1-score: %.4f\"%f1)\n        print('==========================================================')\n        f1_scores.append(f1)\n    \nmax(f1_scores)","execution_count":120,"outputs":[{"output_type":"stream","text":"RandomForestClassifier(n_estimators = 20, max_depth = 2)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 50, max_depth = 2)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 100, max_depth = 2)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 300, max_depth = 2)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 20, max_depth = 5)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 50, max_depth = 5)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 100, max_depth = 5)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 300, max_depth = 5)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 20, max_depth = 10)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 50, max_depth = 10)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 100, max_depth = 10)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\nRandomForestClassifier(n_estimators = 300, max_depth = 10)\n           ===================================          \nconfusion matrix :\n [[56  8]\n [ 3 33]]\nTraining accuracy: 0.9267\nTesting accuracy: 0.8900\nf1-score: 0.8571\n==========================================================\n","name":"stdout"},{"output_type":"execute_result","execution_count":120,"data":{"text/plain":"0.8571428571428571"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"Hence, the `RandomForestClassifier` gives the highest \"f1-score\" = 0.857"},{"metadata":{},"cell_type":"markdown","source":"## 8. Finally, find the best model by using TpotClassifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tpot import TPOTClassifier\ntpot_clf = TPOTClassifier(generations=10, population_size=10, offspring_size=3 , cv=5,\n                          verbosity=2, random_state=42)\ntpot_clf.fit(X_train_full, y_train)","execution_count":121,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=40.0, style=ProgressStyle(des…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\nGeneration 1 - Current best internal CV score: 0.9199999999999999\nGeneration 2 - Current best internal CV score: 0.9199999999999999\nGeneration 3 - Current best internal CV score: 0.9199999999999999\nGeneration 4 - Current best internal CV score: 0.9199999999999999\nGeneration 5 - Current best internal CV score: 0.9199999999999999\nGeneration 6 - Current best internal CV score: 0.9199999999999999\nGeneration 7 - Current best internal CV score: 0.9199999999999999\nGeneration 8 - Current best internal CV score: 0.9199999999999999\nGeneration 9 - Current best internal CV score: 0.9199999999999999\nGeneration 10 - Current best internal CV score: 0.9199999999999999\nBest pipeline: ExtraTreesClassifier(RandomForestClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.6000000000000001, min_samples_leaf=20, min_samples_split=10, n_estimators=100), bootstrap=False, criterion=entropy, max_features=0.35000000000000003, min_samples_leaf=18, min_samples_split=9, n_estimators=100)\n","name":"stdout"},{"output_type":"execute_result","execution_count":121,"data":{"text/plain":"TPOTClassifier(generations=10,\n               log_file=<ipykernel.iostream.OutStream object at 0x7fd9f5666110>,\n               offspring_size=3, population_size=10, random_state=42,\n               verbosity=2)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"tpot_clf.fit(X_train_full, y_train)","execution_count":123,"outputs":[{"output_type":"display_data","data":{"text/plain":"HBox(children=(FloatProgress(value=0.0, description='Optimization Progress', max=40.0, style=ProgressStyle(des…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"stream","text":"\nGeneration 1 - Current best internal CV score: 0.9199999999999999\nGeneration 2 - Current best internal CV score: 0.9199999999999999\nGeneration 3 - Current best internal CV score: 0.9199999999999999\nGeneration 4 - Current best internal CV score: 0.9199999999999999\nGeneration 5 - Current best internal CV score: 0.9199999999999999\nGeneration 6 - Current best internal CV score: 0.9199999999999999\nGeneration 7 - Current best internal CV score: 0.9199999999999999\nGeneration 8 - Current best internal CV score: 0.9199999999999999\nGeneration 9 - Current best internal CV score: 0.9199999999999999\nGeneration 10 - Current best internal CV score: 0.9199999999999999\nBest pipeline: ExtraTreesClassifier(RandomForestClassifier(input_matrix, bootstrap=True, criterion=entropy, max_features=0.6000000000000001, min_samples_leaf=20, min_samples_split=10, n_estimators=100), bootstrap=False, criterion=entropy, max_features=0.35000000000000003, min_samples_leaf=18, min_samples_split=9, n_estimators=100)\n0.89\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(tpot_clf.score(X_test_full, y_test))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}